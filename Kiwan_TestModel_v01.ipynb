{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# First tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! is used to run console commands in jupyter notebooks\n",
    "!pip install -q nbstripout\n",
    "#!pip install LIBRARYNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './KaggleCache/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2'\n",
    "df = pd.read_csv(os.path.join(path, 'full_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## TestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURATION & PFADE\n",
    "# ==========================================\n",
    "# Pfad zu den Bildern (wie von dir angegeben)\n",
    "IMG_DIR = \"./KaggleCache/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2/preprocessed_images\"\n",
    "# Pfad zur CSV (Annahme: liegt im versions/2 Ordner)\n",
    "CSV_PATH = \"./KaggleCache/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2/full_df.csv\"\n",
    "\n",
    "# Hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10       # F√ºr erste Ergebnisse reichen 10, sp√§ter auf 30-50 erh√∂hen\n",
    "IMG_SIZE = 224        # Resize auf 224x224 f√ºr das CNN\n",
    "NUM_CLASSES = 8\n",
    "CLASS_NAMES = ['Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'AMD', 'Hypertension', 'Myopia', 'Other']\n",
    "\n",
    "# Hardware Check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training l√§uft auf: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATEN VORBEREITUNG (WRANGLING)\n",
    "# ==========================================\n",
    "def prepare_data(csv_path):\n",
    "    print(\"Lade und verarbeite Metadaten...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Mapping der ODIR-K√ºrzel auf Indizes\n",
    "    # N, D, G, C, A, H, M, O\n",
    "    target_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "    \n",
    "    # Aufteilen in Linkes und Rechtes Auge (Explosion des Datasets)\n",
    "    left_df = df[['ID', 'Left-Fundus'] + target_cols].copy()\n",
    "    left_df.rename(columns={'Left-Fundus': 'filename'}, inplace=True)\n",
    "    \n",
    "    right_df = df[['ID', 'Right-Fundus'] + target_cols].copy()\n",
    "    right_df.rename(columns={'Right-Fundus': 'filename'}, inplace=True)\n",
    "    \n",
    "    combined_df = pd.concat([left_df, right_df], axis=0)\n",
    "    \n",
    "    # Erstelle Labels (0-7) aus One-Hot Encoding\n",
    "    labels = combined_df[target_cols].values\n",
    "    combined_df['label'] = np.argmax(labels, axis=1)\n",
    "    \n",
    "    # Optional: Pr√ºfen ob Datei existiert (kann man auskommentieren f√ºr Speed)\n",
    "    # combined_df['file_path'] = combined_df['filename'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "full_df = prepare_data(CSV_PATH)\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPLIT (PATIENTEN-BASIERT) 70/15/15\n",
    "# ==========================================\n",
    "# Wichtig: Wir splitten IDs, nicht Bilder, um Data Leakage zu verhindern!\n",
    "patient_ids = full_df['ID'].unique()\n",
    "train_ids, test_ids = train_test_split(patient_ids, test_size=0.3, random_state=42)\n",
    "val_ids, test_ids = train_test_split(test_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = full_df[full_df['ID'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = full_df[full_df['ID'].isin(val_ids)].reset_index(drop=True)\n",
    "test_df = full_df[full_df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"   Datensatz Split:\")\n",
    "print(f\"   Training:   {len(train_df)} Bilder\")\n",
    "print(f\"   Validierung:{len(val_df)} Bilder\")\n",
    "print(f\"   Test:       {len(test_df)} Bilder\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. KLASSENGEWICHTE BERECHNEN\n",
    "# ==========================================\n",
    "# Da der Datensatz extrem unbalanciert ist (viele N/D, wenig A/G etc.)\n",
    "print(\"Berechne Class Weights...\")\n",
    "y_train = train_df['label'].values\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f\"   Gewichte: {class_weights.cpu().numpy()}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. DATASET CLASS & DATALOADER\n",
    "# ==========================================\n",
    "class ODIRDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, row['filename'])\n",
    "        label = row['label']\n",
    "        \n",
    "        try:\n",
    "            # Bild laden\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            # Fallback f√ºr korrupte Bilder (schwarzes Bild)\n",
    "            # print(f\"Warning: Could not load {img_path}\")\n",
    "            image = Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Transformationen (Augmentation f√ºr Train, Resize f√ºr alle)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Loader erstellen\n",
    "train_dataset = ODIRDataset(train_df, IMG_DIR, transform=train_transforms)\n",
    "val_dataset = ODIRDataset(val_df, IMG_DIR, transform=val_test_transforms)\n",
    "test_dataset = ODIRDataset(test_df, IMG_DIR, transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ==========================================\n",
    "# 6. CUSTOM CNN ARCHITEKTUR (VGG-Style)\n",
    "# ==========================================\n",
    "class ODIR_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(ODIR_CNN, self).__init__()\n",
    "        \n",
    "        # Block 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # Output: 112x112\n",
    "        )\n",
    "        # Block 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # Output: 56x56\n",
    "        )\n",
    "        # Block 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # Output: 28x28\n",
    "        )\n",
    "        # Block 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # Output: 14x14\n",
    "        )\n",
    "        \n",
    "        # Flatten Dimension: 256 Channels * 14 * 14 Pixel\n",
    "        self.flatten_dim = 256 * 14 * 14 \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Modell initialisieren\n",
    "model = ODIR_CNN(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Loss Function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# ==========================================\n",
    "# 7. TRAINING LOOP\n",
    "# ==========================================\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "print(f\"Starte Training f√ºr {NUM_EPOCHS} Epochen...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Training\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct_train / total_train\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = 100 * correct_val / total_val\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accs.append(epoch_val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.2f}% | \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.2f}%\")\n",
    "\n",
    "print(\"Training beendet.\")\n",
    "\n",
    "# ==========================================\n",
    "# 8. EVALUATION & VISUALISIERUNG\n",
    "# ==========================================\n",
    "# Plotten der Lernkurven\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Loss √ºber Epochen')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Acc')\n",
    "plt.plot(val_accs, label='Val Acc')\n",
    "plt.title('Accuracy √ºber Epochen')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Finaler Test & Confusion Matrix\n",
    "print(\"Generiere Confusion Matrix auf Testdaten...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Report\n",
    "print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES, zero_division=0))\n",
    "\n",
    "# Matrix Plot\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torchvision\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "#print(f\"Torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import cv2\n",
    "import time\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ==========================================\n",
    "# VERBESSERTE KONFIGURATION\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    \"Project\": \"ODIR-5K Transfer Learning\",\n",
    "    \"Img_Dir\": \"./KaggleCache/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2/preprocessed_images\",\n",
    "    \"CSV_Path\": \"./KaggleCache/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2/full_df.csv\",\n",
    "    \"Batch_Size\": 16,  # Kleiner f√ºr stabileres Training\n",
    "    \"Learning_Rate\": 1e-4,  # Konservativer Start\n",
    "    \"Epochs\": 30,\n",
    "    \"Img_Size\": 224,\n",
    "    \"Num_Classes\": 8,\n",
    "    \"Architecture\": \"EfficientNet-B3 (Pretrained)\",\n",
    "    \"Device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"Mixed_Precision\": True,  # Schnelleres Training mit AMP\n",
    "    \"Early_Stop_Patience\": 7,\n",
    "    \"Gradient_Clip\": 1.0\n",
    "}\n",
    "\n",
    "def print_config(conf):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üî¨ ODIR-5K TRAINING PIPELINE\")\n",
    "    print(\"=\"*50)\n",
    "    for k, v in conf.items():\n",
    "        print(f\"{k:<20}: {v}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "print_config(CONFIG)\n",
    "device = torch.device(CONFIG[\"Device\"])\n",
    "\n",
    "# ==========================================\n",
    "# DATA PREPARATION\n",
    "# ==========================================\n",
    "def prepare_data(csv_path, img_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    target_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "    \n",
    "    left_df = df[['ID', 'Left-Fundus'] + target_cols].copy()\n",
    "    left_df['filename'] = left_df['Left-Fundus']\n",
    "    left_df = left_df.drop('Left-Fundus', axis=1)\n",
    "    \n",
    "    right_df = df[['ID', 'Right-Fundus'] + target_cols].copy()\n",
    "    right_df['filename'] = right_df['Right-Fundus']\n",
    "    right_df = right_df.drop('Right-Fundus', axis=1)\n",
    "    \n",
    "    combined_df = pd.concat([left_df, right_df], axis=0, ignore_index=True)\n",
    "    combined_df['full_path'] = combined_df['filename'].apply(lambda x: os.path.join(img_dir, x))\n",
    "    \n",
    "    # Nur existierende Bilder\n",
    "    combined_df = combined_df[combined_df['full_path'].map(os.path.exists)].reset_index(drop=True)\n",
    "    combined_df['label'] = np.argmax(combined_df[target_cols].values, axis=1)\n",
    "    \n",
    "    print(f\"üìä Datensatz geladen: {len(combined_df)} Bilder\")\n",
    "    print(f\"Klassen-Verteilung:\\n{combined_df['label'].value_counts().sort_index()}\\n\")\n",
    "    \n",
    "    return combined_df, target_cols\n",
    "\n",
    "full_df, target_cols = prepare_data(CONFIG[\"CSV_Path\"], CONFIG[\"Img_Dir\"])\n",
    "\n",
    "# Patient-Level Split (wichtig!)\n",
    "patient_ids = full_df['ID'].unique()\n",
    "train_ids, temp_ids = train_test_split(patient_ids, test_size=0.3, random_state=42, stratify=None)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = full_df[full_df['ID'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = full_df[full_df['ID'].isin(val_ids)].reset_index(drop=True)\n",
    "test_df = full_df[full_df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# Class Weights\n",
    "y_train = train_df['label'].values\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f\"Class Weights: {class_weights.cpu().numpy()}\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# MODERNE AUGMENTATION (Albumentations)\n",
    "# ==========================================\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CONFIG[\"Img_Size\"], CONFIG[\"Img_Size\"]),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.Affine(scale=(0.9, 1.1), translate_percent=0.1, rotate=(-15, 15), p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.GaussNoise(p=0.3),  # Simplified without var_limit\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CONFIG[\"Img_Size\"], CONFIG[\"Img_Size\"]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# DATASET\n",
    "# ==========================================\n",
    "class ODIRDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx]['full_path']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_dataset = ODIRDataset(train_df, transform=train_transform)\n",
    "val_dataset = ODIRDataset(val_df, transform=val_transform)\n",
    "test_dataset = ODIRDataset(test_df, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"Batch_Size\"], \n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG[\"Batch_Size\"], \n",
    "                        shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"Batch_Size\"], \n",
    "                         shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ==========================================\n",
    "# TRANSFER LEARNING MODEL (EfficientNet)\n",
    "# ==========================================\n",
    "class ODIRModel(nn.Module):\n",
    "    def __init__(self, num_classes=8, pretrained=True):\n",
    "        super(ODIRModel, self).__init__()\n",
    "        \n",
    "        # EfficientNet-B3 als Backbone\n",
    "        self.backbone = models.efficientnet_b3(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        \n",
    "        # Anzahl Features aus dem letzten Layer\n",
    "        num_ftrs = self.backbone.classifier[1].in_features\n",
    "        \n",
    "        # Custom Classifier Head\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = ODIRModel(num_classes=CONFIG[\"Num_Classes\"]).to(device)\n",
    "\n",
    "# Optimizer mit unterschiedlichen LRs f√ºr Backbone vs. Head\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.backbone.features.parameters(), 'lr': CONFIG[\"Learning_Rate\"] * 0.1},  # Backbone langsamer\n",
    "    {'params': model.backbone.classifier.parameters(), 'lr': CONFIG[\"Learning_Rate\"]}  # Head schneller\n",
    "], weight_decay=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=CONFIG[\"Mixed_Precision\"])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üß† Modell: EfficientNet-B3\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "print(f\"   Trainable: {trainable_params:,}\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# TRAINING LOOP MIT EARLY STOPPING\n",
    "# ==========================================\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "print(f\"üöÄ Starte Training ({CONFIG['Epochs']} Epochen max)...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(CONFIG[\"Epochs\"]):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision Training\n",
    "        with torch.amp.autocast('cuda', enabled=CONFIG[\"Mixed_Precision\"]):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG[\"Gradient_Clip\"])\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}/{CONFIG['Epochs']} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_acc:.2f}% | \"\n",
    "          f\"Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"   ‚úÖ Neues Best Model (F1: {val_f1:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG[\"Early_Stop_Patience\"]:\n",
    "            print(f\"\\n‚èπÔ∏è  Early Stopping nach {epoch+1} Epochen\")\n",
    "            break\n",
    "\n",
    "duration = (time.time() - start_time) / 60\n",
    "print(f\"\\n‚úÖ Training beendet in {duration:.1f} Minuten\")\n",
    "\n",
    "# ==========================================\n",
    "# FINAL EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà FINALE EVALUATION AUF TEST SET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Test F1-Score: {test_f1:.4f}\\n\")\n",
    "\n",
    "print(\"Detaillierter Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=target_cols, digits=3))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# ==========================================\n",
    "# FIX #1: FOCAL LOSS (statt CrossEntropyLoss)\n",
    "# ==========================================\n",
    "# Fokussiert sich auf schwierige Beispiele\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha  # Class weights\n",
    "        self.gamma = gamma  # Focusing parameter\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # Probability of correct class\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# ==========================================\n",
    "# FIX #2: LABEL SMOOTHING\n",
    "# ==========================================\n",
    "# Verhindert Overconfidence (zu sichere Vorhersagen)\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon=0.1, weight=None):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.weight = weight\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        n_classes = preds.size(-1)\n",
    "        log_preds = F.log_softmax(preds, dim=-1)\n",
    "        \n",
    "        # Smooth labels\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_preds)\n",
    "            true_dist.fill_(self.epsilon / (n_classes - 1))\n",
    "            true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - self.epsilon)\n",
    "        \n",
    "        if self.weight is not None:\n",
    "            loss = -torch.sum(true_dist * log_preds, dim=-1)\n",
    "            loss = loss * self.weight[targets]\n",
    "            return loss.mean()\n",
    "        \n",
    "        return torch.mean(-torch.sum(true_dist * log_preds, dim=-1))\n",
    "\n",
    "# ==========================================\n",
    "# FIX #3: TEST TIME AUGMENTATION (TTA)\n",
    "# ==========================================\n",
    "def tta_predict(model, dataloader, device, n_tta=3):\n",
    "    \"\"\"\n",
    "    Test Time Augmentation - macht mehrere Vorhersagen pro Bild\n",
    "    und mittelt diese f√ºr stabilere Predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Original prediction\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # TTA: Horizontal Flip\n",
    "            outputs_hflip = model(torch.flip(inputs, dims=[3]))\n",
    "            \n",
    "            # TTA: Vertical Flip (optional)\n",
    "            outputs_vflip = model(torch.flip(inputs, dims=[2]))\n",
    "            \n",
    "            # Average predictions\n",
    "            outputs_avg = (outputs + outputs_hflip + outputs_vflip) / 3.0\n",
    "            \n",
    "            _, preds = torch.max(outputs_avg, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# ==========================================\n",
    "# KOMPLETTES RE-TRAINING MIT FIXES\n",
    "# ==========================================\n",
    "print(\"üî• STARTE VERBESSERTES TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model neu initialisieren\n",
    "model_improved = models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_improved.classifier[1].in_features\n",
    "model_improved.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.4),  # Etwas mehr Dropout\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, CONFIG[\"Num_Classes\"])\n",
    ")\n",
    "model_improved = model_improved.to(device)\n",
    "\n",
    "# W√ÑHLE LOSS FUNCTION:\n",
    "# Option A: Focal Loss (beste f√ºr Imbalance)\n",
    "criterion_improved = FocalLoss(alpha=class_weights, gamma=2.0)\n",
    "\n",
    "# Option B: Label Smoothing (verhindert Overconfidence)\n",
    "# criterion_improved = LabelSmoothingCrossEntropy(epsilon=0.1, weight=class_weights)\n",
    "\n",
    "# Optimizer mit h√∂herer Weight Decay\n",
    "optimizer_improved = torch.optim.AdamW([\n",
    "    {'params': model_improved.features.parameters(), 'lr': CONFIG[\"Learning_Rate\"] * 0.1},\n",
    "    {'params': model_improved.classifier.parameters(), 'lr': CONFIG[\"Learning_Rate\"]}\n",
    "], weight_decay=0.02)  # Mehr Regularization\n",
    "\n",
    "scheduler_improved = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_improved, T_0=10, T_mult=2\n",
    ")\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=CONFIG[\"Mixed_Precision\"])\n",
    "\n",
    "# ==========================================\n",
    "# TRAINING LOOP (kompakt)\n",
    "# ==========================================\n",
    "print(f\"‚úÖ Loss: Focal Loss (gamma=2.0)\")\n",
    "print(f\"‚úÖ Weight Decay: 0.02 (mehr Regularization)\")\n",
    "print(f\"‚úÖ Dropout: 0.4/0.3 (gegen Overfitting)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "best_f1_improved = 0.0\n",
    "patience = 0\n",
    "epochs_to_train = 25  # Etwas l√§nger\n",
    "\n",
    "for epoch in range(epochs_to_train):\n",
    "    # Training\n",
    "    model_improved.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_improved.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=CONFIG[\"Mixed_Precision\"]):\n",
    "            outputs = model_improved(inputs)\n",
    "            loss = criterion_improved(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer_improved)\n",
    "        torch.nn.utils.clip_grad_norm_(model_improved.parameters(), 1.0)\n",
    "        scaler.step(optimizer_improved)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model_improved.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_improved(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_acc = 100 * np.mean(np.array(val_preds) == np.array(val_labels))\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}/{epochs_to_train} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Val Acc: {val_acc:.2f}% | Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    scheduler_improved.step()\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_f1 > best_f1_improved:\n",
    "        best_f1_improved = val_f1\n",
    "        torch.save(model_improved.state_dict(), 'best_model_improved.pth')\n",
    "        print(f\"   ‚úÖ New Best (F1: {val_f1:.4f})\")\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 7:\n",
    "            print(f\"\\n‚èπÔ∏è  Early Stop at Epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION MIT TTA\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä EVALUATION: STANDARD vs. TTA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_improved.load_state_dict(torch.load('best_model_improved.pth', weights_only=True))\n",
    "\n",
    "# Standard Evaluation\n",
    "model_improved.eval()\n",
    "test_preds_std, test_labels_std = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_improved(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_preds_std.extend(preds.cpu().numpy())\n",
    "        test_labels_std.extend(labels.cpu().numpy())\n",
    "\n",
    "std_acc = 100 * np.mean(np.array(test_preds_std) == np.array(test_labels_std))\n",
    "std_f1 = f1_score(test_labels_std, test_preds_std, average='weighted')\n",
    "\n",
    "print(f\"\\nüìå STANDARD PREDICTION:\")\n",
    "print(f\"   Accuracy: {std_acc:.2f}%\")\n",
    "print(f\"   F1-Score: {std_f1:.4f}\")\n",
    "\n",
    "# TTA Evaluation\n",
    "print(f\"\\nüìå TTA PREDICTION (3x Augmentation):\")\n",
    "test_preds_tta, test_labels_tta = tta_predict(model_improved, test_loader, device, n_tta=3)\n",
    "\n",
    "tta_acc = 100 * np.mean(test_preds_tta == test_labels_tta)\n",
    "tta_f1 = f1_score(test_labels_tta, test_preds_tta, average='weighted')\n",
    "\n",
    "print(f\"   Accuracy: {tta_acc:.2f}% (+{tta_acc-std_acc:.2f}%)\")\n",
    "print(f\"   F1-Score: {tta_f1:.4f} (+{tta_f1-std_f1:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã DETAILED REPORT (TTA):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(test_labels_tta, test_preds_tta, \n",
    "                          target_names=target_cols, digits=3))\n",
    "\n",
    "print(\"\\nüéØ CONFUSION MATRIX (TTA):\")\n",
    "cm = confusion_matrix(test_labels_tta, test_preds_tta)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ Models saved:\")\n",
    "print(\"   - best_model_improved.pth\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
