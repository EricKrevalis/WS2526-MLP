{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Training with resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! is used to run console commands in jupyter notebooks\n",
    "!pip install -q nbstripout\n",
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './KaggleCache/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2'\n",
    "df = pd.read_csv(os.path.join(path, 'full_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURATION AND DATA ASSUMPTION ---\n",
    "\n",
    "# Define the split ratios\n",
    "TRAIN_RATIO = 0.70\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "# The number of unique classes\n",
    "NUM_CLASSES = 8\n",
    "\n",
    "# --- 2. DATA PREPROCESSING: CONVERT TARGET TO CLASS INDEX ---\n",
    "\n",
    "def target_string_to_index(target_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Converts a string representation of a one-hot list (e.g., '[0,1,0,...]')\n",
    "    into a single integer class index (e.g., 1).\n",
    "    \"\"\"\n",
    "    # Use ast.literal_eval for safe string-to-list conversion\n",
    "    target_list = ast.literal_eval(target_str)\n",
    "    # The index of '1' is the class index\n",
    "    return target_list.index(1)\n",
    "\n",
    "# Apply the conversion to create the necessary column for stratification\n",
    "df['class_index'] = df['target'].apply(target_string_to_index)\n",
    "\n",
    "# Print initial class distribution\n",
    "print(\"--- Initial Class Distribution ---\")\n",
    "print(df['class_index'].value_counts().sort_index())\n",
    "print(\"-\" * 34)\n",
    "\n",
    "# --- 3. STRATIFIED TRAIN / TEST / VAL SPLIT (70/15/15) ---\n",
    "\n",
    "# Step 1: Split into Training (70%) and Temporary (30%) sets\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=(VAL_RATIO + TEST_RATIO), # 0.15 + 0.15 = 0.30\n",
    "    stratify=df['class_index'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split Temporary (30%) into Validation (15%) and Test (15%) sets\n",
    "# test_size = 0.5 because 0.5 of the remaining 0.30 is 0.15\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['class_index'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Verify the final split sizes\n",
    "print(\"\\n--- Final Dataset Sizes ---\")\n",
    "print(f\"Total Samples: {len(df)}\")\n",
    "print(f\"Training Samples (70%): {len(train_df)}\")\n",
    "print(f\"Validation Samples (15%): {len(val_df)}\")\n",
    "print(f\"Test Samples (15%): {len(test_df)}\")\n",
    "\n",
    "# --- 4. CALCULATE INVERSE CLASS FREQUENCY FOR WEIGHTED SAMPLER ---\n",
    "\n",
    "# Count occurrences of each class in the training set\n",
    "class_counts = Counter(train_df['class_index'])\n",
    "# Get total number of samples in the training set\n",
    "total_samples = len(train_df)\n",
    "# Calculate the frequency of each class\n",
    "class_frequencies = {i: class_counts.get(i, 0) / total_samples for i in range(NUM_CLASSES)}\n",
    "\n",
    "# Calculate inverse frequency (or weight)\n",
    "# The weight for a class is inversely proportional to its frequency: w_i = 1 / f_i\n",
    "# We use this as the basis for the PyTorch WeightedRandomSampler\n",
    "class_weights = {\n",
    "    i: 1.0 / class_frequencies[i]\n",
    "    for i in range(NUM_CLASSES) if class_frequencies[i] > 0\n",
    "}\n",
    "\n",
    "# Convert weights to a tensor (PyTorch requires this format)\n",
    "# Note: PyTorch expects weights ordered by class index [w0, w1, w2, ...]\n",
    "# Use max(class_weights.values()) for normalization, but absolute inverse frequency is fine too\n",
    "inverse_weights = [class_weights.get(i, 0.0) for i in range(NUM_CLASSES)]\n",
    "# Normalize the weights so the smallest weight is 1.0\n",
    "max_weight = max(inverse_weights)\n",
    "normalized_weights = [w / max_weight for w in inverse_weights]\n",
    "\n",
    "# Print the final class weights for review\n",
    "print(\"\\n--- Training Set Class Weights (Normalized) ---\")\n",
    "print(f\"Class Frequencies: {class_frequencies}\")\n",
    "print(f\"Inverse Weights: {normalized_weights}\")\n",
    "# Store the weights as a numpy array for easy conversion to PyTorch tensor later\n",
    "class_weights_np = np.array(normalized_weights, dtype=np.float32)\n",
    "\n",
    "print(\"\\n--- Stratification Check (Training Set) ---\")\n",
    "print(train_df['class_index'].value_counts(normalize=True).sort_index() * 100)\n",
    "print(\"\\n--- Stratification Check (Validation Set) ---\")\n",
    "print(val_df['class_index'].value_counts(normalize=True).sort_index() * 100)\n",
    "print(\"\\n--- Stratification Check (Test Set) ---\")\n",
    "print(test_df['class_index'].value_counts(normalize=True).sort_index() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CUSTOM LOSS FUNCTION: FOCAL LOSS ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss für Imbalanced Datasets.\n",
    "    Reduziert den Loss für gut klassifizierte Beispiele (p > 0.5) und \n",
    "    fokussiert sich auf harte, falsch klassifizierte Beispiele.\n",
    "    \n",
    "    Formel: FL(p_t) = -alpha * (1 - p_t)^gamma * log(p_t)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha # Gewichtung der Klassen (optional)\n",
    "        self.gamma = gamma # Focusing Parameter (Standard: 2.0)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Standard Cross Entropy berechnen (ohne Reduction, damit wir gewichten können)\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
    "        \n",
    "        # p_t berechnen (Wahrscheinlichkeit der wahren Klasse)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Focal Term: (1 - pt)^gamma\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Model Architecture: ResNet18 with Feature Fusion\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "class ResNet18WithSideInfo(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid Model: Combines a pre-trained ResNet18 backbone for image feature extraction\n",
    "    with an explicit side-vector input (Left/Right eye encoding).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(ResNet18WithSideInfo, self).__init__()\n",
    "        \n",
    "        # 1. Load ResNet18 Backbone (Pre-trained on ImageNet)\n",
    "        # We use ResNet18 as it offers the best trade-off between performance and \n",
    "        # generalization for this dataset size (avoiding overfitting seen in ResNet50).\n",
    "        print(\"Loading ResNet18 backbone (ImageNet weights)...\")\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # 2. Remove the original classification head\n",
    "        # ResNet18 outputs 512 features before the final layer\n",
    "        self.num_ftrs = self.resnet.fc.in_features \n",
    "        self.resnet.fc = nn.Identity() # Passthrough layer\n",
    "        \n",
    "        # 3. Define Custom Head (Feature Fusion)\n",
    "        # Input: 512 (Image Features) + 2 (Side Info One-Hot) -> Output: 8 Classes\n",
    "        self.final_fc = nn.Linear(self.num_ftrs + 2, num_classes)\n",
    "\n",
    "    def forward(self, image, side_vector):\n",
    "        # Extract image features\n",
    "        features = self.resnet(image)\n",
    "        # Concatenate features with side information\n",
    "        combined = torch.cat((features, side_vector), dim=1)\n",
    "        # Final classification\n",
    "        output = self.final_fc(combined)\n",
    "        return output\n",
    "\n",
    "# Initialization\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18WithSideInfo(num_classes=8)\n",
    "model.to(device)\n",
    "print(f\"ResNet18 Side-Aware Model initialized on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Data Pipeline: Custom Dataset & Mirroring Strategy\n",
    "\n",
    "# --- SAMPLER SETUP ---\n",
    "# Map class weights to individual samples to handle class imbalance\n",
    "sample_weights = train_df['class_index'].apply(lambda x: class_weights_np[x]).values\n",
    "\n",
    "# Create WeightedRandomSampler\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# --- TRANSFORMS ---\n",
    "# Standard ImageNet normalization stats\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training Transforms (High-Res 512x512)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), \n",
    "    # NOTE: No RandomHorizontalFlip here! \n",
    "    # Mirroring is handled logically in the Dataset class to align optic disc position.\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Validation/Test Transforms (Deterministic)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# --- CUSTOM DATASET CLASS ---\n",
    "class OcularDatasetSideAware(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset that handles image loading and side-specific preprocessing.\n",
    "    Implements the 'Mirroring Trick': Right eyes are flipped to structurally resemble left eyes.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_dir = os.path.join(self.root_dir, \"preprocessed_images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['filename']\n",
    "        label = row['class_index']\n",
    "        \n",
    "        # 1. Side Detection & Encoding\n",
    "        is_right_eye = 'right' in img_name\n",
    "        # One-Hot Encoding: [1, 0] for Left, [0, 1] for Right\n",
    "        side_vector = torch.tensor([0.0, 1.0]) if is_right_eye else torch.tensor([1.0, 0.0])\n",
    "\n",
    "        # 2. Load Image\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 3. Apply Mirroring Trick\n",
    "        # Flip right eyes horizontally so optic disc is always on the same side (nasal)\n",
    "        if is_right_eye:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # 4. Apply Transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, side_vector, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# --- DATALOADERS ---\n",
    "# Note: BATCH_SIZE is set in the training configuration below.\n",
    "\n",
    "train_dataset = OcularDatasetSideAware(train_df, path, transform=train_transforms)\n",
    "val_dataset = OcularDatasetSideAware(val_df, path, transform=val_test_transforms)\n",
    "test_dataset = OcularDatasetSideAware(test_df, path, transform=val_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Training Configuration & Execution\n",
    "\n",
    "# --- HYPERPARAMETERS ---\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- LOADER INITIALIZATION ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# --- MODEL SETUP ---\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "\n",
    "# MANUAL WEIGHTS\n",
    "weights_modified = class_weights_np.copy()\n",
    "\n",
    "# Index 5 = Hypertension.\n",
    "# Wir sagen dem Modell: \"Ein Fehler hier ist 5x so schlimm wie sonst!\"\n",
    "# Damit zwingen wir es, die 2 Treffer von eben zu reproduzieren, aber stabil.\n",
    "weights_modified[5] = weights_modified[5] * 5.0\n",
    "print(\"Manuelle Gewichte aktiv:\", weights_modified)\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights_np, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = FocalLoss(alpha=None, gamma=2.0).to(device)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# --- TRAINING HELPER FUNCTIONS ---\n",
    "def train_one_epoch_side(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, sides, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, sides, labels = images.to(device), sides.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, sides)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate_epoch_side(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, sides, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, sides, labels = images.to(device), sides.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images, sides)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    return running_loss / len(dataloader.dataset), accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "# --- MAIN TRAINING LOOP ---\n",
    "history_train_loss = []\n",
    "history_val_loss = []\n",
    "history_val_acc = []\n",
    "history_val_f1 = []\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "print(f\"\\n--- Starting Optimized Training (ResNet18 + Side Aware + Focal Loss) ---\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss = train_one_epoch_side(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_f1 = validate_epoch_side(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_f1)\n",
    "    \n",
    "    history_train_loss.append(train_loss)\n",
    "    history_val_loss.append(val_loss)\n",
    "    history_val_acc.append(val_acc)\n",
    "    history_val_f1.append(val_f1)\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Train Loss {train_loss:.4f} | Val F1 {val_f1:.4f} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    \n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_resnet18_focal.pth')\n",
    "        print(\"  --> Best model saved as 'best_resnet18_focal.pth'!\")\n",
    "\n",
    "print(f\"Training Complete. Best Validation F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Evaluation & Visualization\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CLASS_NAMES = [\n",
    "    \"Normal\", \"Diabetic\", \"Glaucoma\", \"Cataract\", \n",
    "    \"Macular Deg.\", \"Hypertension\", \"Myopia\", \"Other\"\n",
    "]\n",
    "\n",
    "# --- PLOTTING HELPERS ---\n",
    "def plot_training_metrics(train_loss, val_loss, val_f1, val_acc):\n",
    "    \"\"\"Visualizes Loss and Metrics over epochs.\"\"\"\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss (CrossEntropy)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Metrics Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_f1, 'go-', label='Validation F1-Score (Weighted)')\n",
    "    plt.plot(epochs, val_acc, 'yo--', label='Validation Accuracy')\n",
    "    plt.title('Validation Performance')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    \"\"\"Plots a seaborn heatmap of the confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(true_labels, predictions, labels=np.arange(len(class_names)))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def get_test_predictions_side_aware(model, dataloader, device):\n",
    "    \"\"\"Runs inference on the test set handling the dual-input requirement.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, sides, labels in tqdm(dataloader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            sides = sides.to(device)\n",
    "            outputs = model(images, sides)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "# 1. Plot Training History\n",
    "print(\"\\n--- Plotting Training Metrics ---\")\n",
    "if 'history_train_loss' in locals() and len(history_train_loss) > 0:\n",
    "    plot_training_metrics(history_train_loss, history_val_loss, history_val_f1, history_val_acc)\n",
    "else:\n",
    "    print(\"No training history found in memory.\")\n",
    "\n",
    "# 2. Evaluate on Unseen Test Set\n",
    "print(\"\\n--- Evaluating Best Model on Test Set ---\")\n",
    "\n",
    "# Load best weights\n",
    "model.load_state_dict(torch.load('best_resnet18_focal.pth', weights_only=True))\n",
    "model.to(device)\n",
    "\n",
    "# Generate Predictions\n",
    "test_preds, test_labels = get_test_predictions_side_aware(model, test_loader, device)\n",
    "\n",
    "# Calculate Final Metrics\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "test_f1 = f1_score(test_labels, test_preds, average='weighted', zero_division=0) \n",
    "\n",
    "print(f\"\\n=== FINAL TEST RESULTS (ResNet18) ===\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test F1-Score (Weighted): {test_f1:.4f}\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_confusion_matrix(test_labels, test_preds, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
